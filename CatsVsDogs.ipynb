{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae313a9-84dc-4273-9049-37cbd0e07d00",
   "metadata": {},
   "source": [
    "# Dogs Vs Cats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbeb3fc4-3751-4776-b6bb-e2dfbe2364c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02643d15-fca7-418c-ab2f-6df97b15097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b445d-b2d5-43da-a8b9-b69b696279e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87349f5-8235-4ab9-9d7e-29b9dbf374c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "# use for large dataset, will send data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6692d-0127-49a8-b437-4a6c085d9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'trainDatasetPath',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',  # will give 0 to cats and 1 to dogs\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)  # will give same size to images\n",
    ")\n",
    "\n",
    "validation_dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'testDatasetPath',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',  # will give 0 to cats and 1 to dogs\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)  # will give same size to images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b5beb22-a0ec-4629-a13c-f189fb44c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# from (0-255) -> (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe76b4-f8be-4c2e-be94-0218046ed17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image, label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "# storing again in train and validation dataset\n",
    "train_dataset = train_ds.map(process)\n",
    "validation_dataset = validation_dataset.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44383d7f-6a47-4826-a7f0-dbc85f37bcd3",
   "metadata": {},
   "source": [
    "**CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22eaa8-1bc9-4f47-88a2-d3259924034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3,3), padding = 'valid', activation = 'relu', input_shape = (256,256,3)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), padding = 'valid', activation = 'relu')\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3,3), padding = 'valid', activation = 'relu')\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575305c5-3b3b-4371-890e-b2580ea2f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3c4e7-0419-4c0a-a085-98efb42b3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf467ae4-3739-4ea7-aef9-89ee4e5d5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs = 10, validation_data = validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1fd63-9541-432a-98f7-045de3c726e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will execute in batches due to generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0be7f0-7b9f-4dff-ace3-bcb29d2a3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], color = 'red', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'blue', label = 'validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f21fff-ff82-4182-bfed-c46b0655cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color = 'red', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'blue', label = 'validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3438d26-e648-4d2e-b4a6-042672dd57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ways to reduce Overfitting\n",
    "# 1. Add more data\n",
    "# 2. Data Augmentation\n",
    "# 3. L1/L2 Regularizer\n",
    "# 4. Dropout\n",
    "# 5. Batch Norm\n",
    "# 6. Reduce Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a5e25-1bff-4fa6-9713-69357e71a4cf",
   "metadata": {},
   "source": [
    "**Taking Image input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c74367-1a3b-4add-a208-3c2e80cc9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\prajwal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\prajwal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f0db8f-9f69-4cf0-a9d9-660d9c0ff740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09539558-f6dc-4733-a90f-333c9fe4f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('pathOfTestImage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e9322-4543-4f88-ab8b-391667708e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfe235-1591-46ca-bd5d-358fe13d354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea1424-c245-492a-90ce-0bba86f2506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.resize(test_image, (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee51284-b2b0-4a63-99b8-54e447be27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_image.reshape((1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f5c60-70cd-4a18-8e29-f3d382867fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc1f8a-afd5-4deb-8c1c-a75015cc5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will return 1 if dog else 0 for cat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
